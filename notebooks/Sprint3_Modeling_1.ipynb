{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Puissance administrative</th>\n",
       "      <th>Puissance maximale (kW)</th>\n",
       "      <th>Consommation urbaine (l/100km)</th>\n",
       "      <th>Consommation extra-urbaine (l/100km)</th>\n",
       "      <th>Consommation mixte (l/100km)</th>\n",
       "      <th>CO2 (g/km)</th>\n",
       "      <th>CO type I (g/km)</th>\n",
       "      <th>NOX (g/km)</th>\n",
       "      <th>HC+NOX (g/km)</th>\n",
       "      <th>Particules (g/km)</th>\n",
       "      <th>...</th>\n",
       "      <th>Carrosserie_MONOSPACE</th>\n",
       "      <th>Carrosserie_MONOSPACE COMPACT</th>\n",
       "      <th>Carrosserie_TS TERRAINS/CHEMINS</th>\n",
       "      <th>gamme_ECONOMIQUE</th>\n",
       "      <th>gamme_INFERIEURE</th>\n",
       "      <th>gamme_LUXE</th>\n",
       "      <th>gamme_MOY-INF</th>\n",
       "      <th>gamme_MOY-INFER</th>\n",
       "      <th>gamme_MOY-SUPER</th>\n",
       "      <th>gamme_SUPERIEURE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.249408</td>\n",
       "      <td>0.274939</td>\n",
       "      <td>0.247934</td>\n",
       "      <td>0.283262</td>\n",
       "      <td>0.284404</td>\n",
       "      <td>0.617861</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.519403</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.209357</td>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.167382</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>0.091057</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.167382</td>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.063344</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>0.160584</td>\n",
       "      <td>0.115702</td>\n",
       "      <td>0.167382</td>\n",
       "      <td>0.196330</td>\n",
       "      <td>0.063344</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.209357</td>\n",
       "      <td>0.167883</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.175966</td>\n",
       "      <td>0.205505</td>\n",
       "      <td>0.057113</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>0.578358</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.209357</td>\n",
       "      <td>0.167883</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.175966</td>\n",
       "      <td>0.205505</td>\n",
       "      <td>0.057113</td>\n",
       "      <td>0.088347</td>\n",
       "      <td>0.578358</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1375</td>\n",
       "      <td>0.249408</td>\n",
       "      <td>0.279805</td>\n",
       "      <td>0.264463</td>\n",
       "      <td>0.291845</td>\n",
       "      <td>0.291743</td>\n",
       "      <td>0.617861</td>\n",
       "      <td>0.016802</td>\n",
       "      <td>0.529851</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.209357</td>\n",
       "      <td>0.163017</td>\n",
       "      <td>0.132231</td>\n",
       "      <td>0.171674</td>\n",
       "      <td>0.205505</td>\n",
       "      <td>0.194185</td>\n",
       "      <td>0.091057</td>\n",
       "      <td>0.567164</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>0.165450</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.171674</td>\n",
       "      <td>0.201835</td>\n",
       "      <td>0.063344</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.163845</td>\n",
       "      <td>0.165450</td>\n",
       "      <td>0.123967</td>\n",
       "      <td>0.171674</td>\n",
       "      <td>0.201835</td>\n",
       "      <td>0.063344</td>\n",
       "      <td>0.080217</td>\n",
       "      <td>0.511194</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 533 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Puissance administrative  Puissance maximale (kW)  \\\n",
       "0                    0.1375                 0.249408   \n",
       "1                    0.1000                 0.209357   \n",
       "2                    0.0750                 0.163845   \n",
       "3                    0.0750                 0.163845   \n",
       "4                    0.1000                 0.209357   \n",
       "5                    0.1000                 0.209357   \n",
       "6                    0.1375                 0.249408   \n",
       "7                    0.1000                 0.209357   \n",
       "8                    0.0750                 0.163845   \n",
       "9                    0.0750                 0.163845   \n",
       "\n",
       "   Consommation urbaine (l/100km)  Consommation extra-urbaine (l/100km)  \\\n",
       "0                        0.274939                              0.247934   \n",
       "1                        0.160584                              0.123967   \n",
       "2                        0.160584                              0.115702   \n",
       "3                        0.160584                              0.115702   \n",
       "4                        0.167883                              0.123967   \n",
       "5                        0.167883                              0.123967   \n",
       "6                        0.279805                              0.264463   \n",
       "7                        0.163017                              0.132231   \n",
       "8                        0.165450                              0.123967   \n",
       "9                        0.165450                              0.123967   \n",
       "\n",
       "   Consommation mixte (l/100km)  CO2 (g/km)  CO type I (g/km)  NOX (g/km)  \\\n",
       "0                      0.283262    0.284404          0.617861    0.016802   \n",
       "1                      0.167382    0.200000          0.194185    0.091057   \n",
       "2                      0.167382    0.196330          0.063344    0.080217   \n",
       "3                      0.167382    0.196330          0.063344    0.080217   \n",
       "4                      0.175966    0.205505          0.057113    0.088347   \n",
       "5                      0.175966    0.205505          0.057113    0.088347   \n",
       "6                      0.291845    0.291743          0.617861    0.016802   \n",
       "7                      0.171674    0.205505          0.194185    0.091057   \n",
       "8                      0.171674    0.201835          0.063344    0.080217   \n",
       "9                      0.171674    0.201835          0.063344    0.080217   \n",
       "\n",
       "   HC+NOX (g/km)  Particules (g/km)  ...  Carrosserie_MONOSPACE  \\\n",
       "0       0.519403           0.003279  ...                    0.0   \n",
       "1       0.567164           0.004918  ...                    0.0   \n",
       "2       0.511194           0.001639  ...                    0.0   \n",
       "3       0.511194           0.001639  ...                    0.0   \n",
       "4       0.578358           0.001639  ...                    0.0   \n",
       "5       0.578358           0.001639  ...                    0.0   \n",
       "6       0.529851           0.003279  ...                    0.0   \n",
       "7       0.567164           0.004918  ...                    0.0   \n",
       "8       0.511194           0.001639  ...                    0.0   \n",
       "9       0.511194           0.001639  ...                    0.0   \n",
       "\n",
       "   Carrosserie_MONOSPACE COMPACT  Carrosserie_TS TERRAINS/CHEMINS  \\\n",
       "0                            0.0                              0.0   \n",
       "1                            0.0                              0.0   \n",
       "2                            0.0                              0.0   \n",
       "3                            0.0                              0.0   \n",
       "4                            0.0                              0.0   \n",
       "5                            0.0                              0.0   \n",
       "6                            0.0                              0.0   \n",
       "7                            0.0                              0.0   \n",
       "8                            0.0                              0.0   \n",
       "9                            0.0                              0.0   \n",
       "\n",
       "   gamme_ECONOMIQUE  gamme_INFERIEURE  gamme_LUXE  gamme_MOY-INF  \\\n",
       "0               0.0               0.0         0.0            0.0   \n",
       "1               0.0               0.0         0.0            0.0   \n",
       "2               0.0               0.0         0.0            0.0   \n",
       "3               0.0               0.0         0.0            0.0   \n",
       "4               0.0               0.0         0.0            0.0   \n",
       "5               0.0               0.0         0.0            0.0   \n",
       "6               0.0               0.0         0.0            0.0   \n",
       "7               0.0               0.0         0.0            0.0   \n",
       "8               0.0               0.0         0.0            0.0   \n",
       "9               0.0               0.0         0.0            0.0   \n",
       "\n",
       "   gamme_MOY-INFER  gamme_MOY-SUPER  gamme_SUPERIEURE  \n",
       "0              0.0              1.0               0.0  \n",
       "1              0.0              1.0               0.0  \n",
       "2              0.0              1.0               0.0  \n",
       "3              0.0              1.0               0.0  \n",
       "4              0.0              1.0               0.0  \n",
       "5              0.0              1.0               0.0  \n",
       "6              0.0              1.0               0.0  \n",
       "7              0.0              1.0               0.0  \n",
       "8              0.0              1.0               0.0  \n",
       "9              0.0              1.0               0.0  \n",
       "\n",
       "[10 rows x 533 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../notebooks/Clean_Data_Preprocessed.csv'  # Use '..' to go up one level\n",
    "\n",
    "df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.6e-05\n"
     ]
    }
   ],
   "source": [
    "# Separating target feature from the remaining features\n",
    "X = df.drop(columns=['CO2 (g/km)'])  # Features\n",
    "y = df['CO2 (g/km)']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", round(mse,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.00266\n",
      "Root Mean Squared Error (RMSE): 0.005086\n",
      "R-squared (R2): 0.99459\n",
      "Mean Absolute Percentage Error (MAPE): 0.00973\n",
      "Median Absolute Error (MedAE): 0.001631\n",
      "Max Error: 0.091257\n",
      "Mean Squared Logarithmic Error (MSLE): 1.6e-05\n",
      "R-squared Adjusted (R2 Adjusted): 0.994244\n",
      "Explained Variance Score: 0.99459\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error, median_absolute_error, max_error, mean_squared_log_error, explained_variance_score\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "\n",
    "# Calculate R-squared (R2)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.000592\n",
      "Mean Absolute Error (MAE): 0.017638\n",
      "Root Mean Squared Error (RMSE): 0.024329\n",
      "R-squared (R2): 0.876186\n",
      "Mean Absolute Percentage Error (MAPE): 0.062014\n",
      "Median Absolute Error (MedAE): 0.013498\n",
      "Max Error: 0.170917\n",
      "Mean Squared Logarithmic Error (MSLE): 0.000351\n",
      "R-squared Adjusted (R2 Adjusted): 0.868263\n",
      "Explained Variance Score: 0.876187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Separating target feature from the remaining features\n",
    "X = df.drop(columns=['CO2 (g/km)'])  # Features\n",
    "y = df['CO2 (g/km)']  # Target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "\n",
    "# Fit PCA on training data and transform both training and testing data\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Initialize and train a linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 2.9e-05\n",
      "Mean Absolute Error (MAE): 0.003036\n",
      "Root Mean Squared Error (RMSE): 0.005351\n",
      "R-squared (R2): 0.994011\n",
      "Mean Absolute Percentage Error (MAPE): 0.010805\n",
      "Median Absolute Error (MedAE): 0.002148\n",
      "Max Error: 0.09206\n",
      "Mean Squared Logarithmic Error (MSLE): 1.7e-05\n",
      "R-squared Adjusted (R2 Adjusted): 0.993628\n",
      "Explained Variance Score: 0.994011\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Ridge Regression model with a specific alpha (regularization strength)\n",
    "alpha = 1.0  # We can adjust this value based on cross-validation\n",
    "ridge_model = Ridge(alpha=alpha)\n",
    "\n",
    "# Train the Ridge Regression model\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False) \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha: 0.1\n",
      "Mean Squared Error (MSE): 2.7e-05\n",
      "Mean Absolute Error (MAE): 0.002803\n",
      "Root Mean Squared Error (RMSE): 0.005201\n",
      "R-squared (R2): 0.994342\n",
      "Mean Absolute Percentage Error (MAPE): 0.010141\n",
      "Median Absolute Error (MedAE): 0.001923\n",
      "Max Error: 0.092525\n",
      "Mean Squared Logarithmic Error (MSLE): 1.6e-05\n",
      "R-squared Adjusted (R2 Adjusted): 0.99398\n",
      "Explained Variance Score: 0.994342\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "import numpy as np\n",
    "# Define a range of alpha values to try\n",
    "alphas = [0.1, 1.0, 10.0]\n",
    "\n",
    "# Initialize RidgeCV with the list of alphas and specify cv parameter for cross-validation\n",
    "ridge_cv = RidgeCV(alphas=alphas, cv=5)  # cv=5 for 5-fold cross-validation\n",
    "\n",
    "# Fit the model\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "# Get the optimal alpha\n",
    "optimal_alpha = ridge_cv.alpha_\n",
    "print(\"Optimal Alpha:\", optimal_alpha)\n",
    "# Make predictions on the test set\n",
    "y_pred = ridge_cv.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha: 1\n",
      "Mean Squared Error (MSE): 0.000588\n",
      "Mean Absolute Error (MAE): 0.017591\n",
      "Root Mean Squared Error (RMSE): 0.024243\n",
      "R-squared (R2): 0.87706\n",
      "Mean Absolute Percentage Error (MAPE): 0.061786\n",
      "Median Absolute Error (MedAE): 0.01336\n",
      "Max Error: 0.170499\n",
      "Mean Squared Logarithmic Error (MSLE): 0.000348\n",
      "R-squared Adjusted (R2 Adjusted): 0.876809\n",
      "Explained Variance Score: 0.877062\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Apply dimensionality reduction technique (e.g., PCA)\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of variance\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply Ridge Regression with cross-validation\n",
    "param_grid = {'alpha': [0.1, 1, 10]}  # Example alpha values\n",
    "ridge = Ridge()\n",
    "grid_search = GridSearchCV(ridge, param_grid, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the optimal alpha\n",
    "optimal_alpha = grid_search.best_params_['alpha']\n",
    "print(\"Optimal Alpha:\", optimal_alpha)\n",
    "\n",
    "# Apply Ridge Regression with the optimal alpha\n",
    "ridge_model = Ridge(alpha=optimal_alpha)\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# 4. Evaluate the model\n",
    "y_pred = ridge_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.004781\n",
      "Mean Absolute Error (MAE): 0.051255\n",
      "Root Mean Squared Error (RMSE): 0.069143\n",
      "R-squared (R2): -3.8e-05\n",
      "Mean Absolute Percentage Error (MAPE): 0.195764\n",
      "Median Absolute Error (MedAE): 0.031214\n",
      "Max Error: 0.203649\n",
      "Mean Squared Logarithmic Error (MSLE): 0.002842\n",
      "R-squared Adjusted (R2 Adjusted): -0.064028\n",
      "Explained Variance Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize and train the Lasso Regression model\n",
    "alpha = 0.1  # regularization parameter\n",
    "lasso_model = Lasso(alpha=alpha)\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Alpha: 0.01\n",
      "Mean Squared Error (MSE): 0.002982\n",
      "Mean Absolute Error (MAE): 0.037452\n",
      "Root Mean Squared Error (RMSE): 0.054605\n",
      "R-squared (R2): 0.376282\n",
      "Mean Absolute Percentage Error (MAPE): 0.140266\n",
      "Median Absolute Error (MedAE): 0.023212\n",
      "Max Error: 0.237502\n",
      "Mean Squared Logarithmic Error (MSLE): 0.001758\n",
      "R-squared Adjusted (R2 Adjusted): 0.336371\n",
      "Explained Variance Score: 0.376283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the Lasso Regression model\n",
    "lasso_model = Lasso()\n",
    "\n",
    "# Define the alpha values to search\n",
    "alphas = [0.01, 0.1, 1.0, 10.0]  # Example values\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': alphas}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=lasso_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "\n",
    "# Perform GridSearchCV\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Get the best alpha value\n",
    "optimal_alpha = grid_search.best_params_['alpha']\n",
    "\n",
    "# Print the optimal alpha value\n",
    "print(\"Optimal Alpha:\", optimal_alpha)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Lasso Regression model\n",
    "lasso_model = Lasso(alpha=optimal_alpha)  # Use the optimal alpha obtained from GridSearchCV\n",
    "\n",
    "# Train the Lasso Regression model\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.004781\n",
      "Mean Absolute Error (MAE): 0.051255\n",
      "Root Mean Squared Error (RMSE): 0.069143\n",
      "R-squared (R2): -3.8e-05\n",
      "Mean Absolute Percentage Error (MAPE): 0.195764\n",
      "Median Absolute Error (MedAE): 0.031214\n",
      "Max Error: 0.203649\n",
      "Mean Squared Logarithmic Error (MSLE): 0.002842\n",
      "R-squared Adjusted (R2 Adjusted): -0.064028\n",
      "Explained Variance Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the ElasticNet Regression model\n",
    "alpha = 0.1  # regularization parameter\n",
    "l1_ratio = 0.5  # mixing parameter, 0.0 for L2 penalty, 1.0 for L1 penalty\n",
    "elasticnet_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "elasticnet_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = elasticnet_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.01, 'l1_ratio': 0.1}\n",
      "Mean Squared Error (MSE): 0.000778\n",
      "Mean Absolute Error (MAE): 0.018575\n",
      "Root Mean Squared Error (RMSE): 0.027892\n",
      "R-squared (R2): 0.83726\n",
      "Mean Absolute Percentage Error (MAPE): 0.06638\n",
      "Median Absolute Error (MedAE): 0.011893\n",
      "Max Error: 0.186258\n",
      "Mean Squared Logarithmic Error (MSLE): 0.000448\n",
      "R-squared Adjusted (R2 Adjusted): 0.826846\n",
      "Explained Variance Score: 0.837264\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the ElasticNet model\n",
    "elastic_net = ElasticNet()\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.01, 0.1, 1.0, 10.0],  # Regularization strength\n",
    "    'l1_ratio': [0.1, 0.5, 0.7, 0.9]  # Mixing parameter\n",
    "}\n",
    "\n",
    "# Perform grid search cross-validation\n",
    "grid_search = GridSearchCV(estimator=elastic_net, param_grid=param_grid, cv=10, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the ElasticNet model with the best hyperparameters\n",
    "best_elastic_net = ElasticNet(alpha=best_params['alpha'], l1_ratio=best_params['l1_ratio'])\n",
    "best_elastic_net.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_elastic_net.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 5e-06\n",
      "Mean Absolute Error (MAE): 0.000171\n",
      "Root Mean Squared Error (RMSE): 0.002197\n",
      "R-squared (R2): 0.99899\n",
      "Mean Absolute Percentage Error (MAPE): 0.000686\n",
      "Median Absolute Error (MedAE): 0.0\n",
      "Max Error: 0.170642\n",
      "Mean Squared Logarithmic Error (MSLE): 3e-06\n",
      "R-squared Adjusted (R2 Adjusted): 0.998925\n",
      "Explained Variance Score: 0.99899\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import explained_variance_score\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Decision Tree Regression model\n",
    "dt_regressor = DecisionTreeRegressor(random_state=42)\n",
    "dt_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = dt_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "# Calculate Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 7.5e-05\n",
      "Mean Absolute Error (MAE): 0.001316\n",
      "Root Mean Squared Error (RMSE): 0.008683\n",
      "R-squared (R2): 0.98423\n",
      "Mean Absolute Percentage Error (MAPE): 0.005516\n",
      "Median Absolute Error (MedAE): 0.0\n",
      "Max Error: 0.255046\n",
      "Mean Squared Logarithmic Error (MSLE): 4.5e-05\n",
      "R-squared Adjusted (R2 Adjusted): 0.983221\n",
      "Explained Variance Score: 0.98423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Assuming X contains your features and y contains the target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=0.95)  # Retain 95% of the variance\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Initialize and train a decision tree regressor\n",
    "model = DecisionTreeRegressor(random_state=42)\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_pca)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4e-06\n",
      "Mean Absolute Error (MAE): 0.000201\n",
      "Root Mean Squared Error (RMSE): 0.002062\n",
      "R-squared (R2): 0.99911\n",
      "Mean Absolute Percentage Error (MAPE): 0.000851\n",
      "Median Absolute Error (MedAE): 0.0\n",
      "Max Error: 0.152991\n",
      "Mean Squared Logarithmic Error (MSLE): 3e-06\n",
      "R-squared Adjusted (R2 Adjusted): 0.999053\n",
      "Explained Variance Score: 0.99911\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using various metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Halimeh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 5e-06\n",
      "Mean Absolute Error (MAE): 0.000219\n",
      "Root Mean Squared Error (RMSE): 0.00213\n",
      "R-squared (R2): 0.999051\n",
      "Mean Absolute Percentage Error (MAPE): 0.000938\n",
      "Median Absolute Error (MedAE): 0.0\n",
      "Max Error: 0.150826\n",
      "Mean Squared Logarithmic Error (MSLE): 3e-06\n",
      "R-squared Adjusted (R2 Adjusted): 0.998991\n",
      "Explained Variance Score: 0.999051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Initialize Bagging Regressor with Decision Tree base estimator\n",
    "bagged_dt = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=10, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "bagged_dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bagged_dt.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Halimeh\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.001666\n",
      "Mean Absolute Error (MAE): 0.031755\n",
      "Root Mean Squared Error (RMSE): 0.040816\n",
      "R-squared (R2): 0.65152\n",
      "Mean Absolute Percentage Error (MAPE): 0.115697\n",
      "Median Absolute Error (MedAE): 0.021914\n",
      "Max Error: 0.103569\n",
      "Mean Squared Logarithmic Error (MSLE): 0.000986\n",
      "R-squared Adjusted (R2 Adjusted): 0.629221\n",
      "Explained Variance Score: 0.654758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Initialize Bagging Regressor with SVR base estimator\n",
    "bagged_svm = BaggingRegressor(base_estimator=SVR(), n_estimators=20, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "bagged_svm.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = bagged_svm.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 0.000178\n",
      "Mean Absolute Error (MAE): 0.010845\n",
      "Root Mean Squared Error (RMSE): 0.013347\n",
      "R-squared (R2): 0.962735\n",
      "Mean Absolute Percentage Error (MAPE): 0.035307\n",
      "Median Absolute Error (MedAE): 0.008316\n",
      "Max Error: 0.131194\n",
      "Mean Squared Logarithmic Error (MSLE): 0.000102\n",
      "R-squared Adjusted (R2 Adjusted): 0.960351\n",
      "Explained Variance Score: 0.973949\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# Initialize AdaBoostRegressor\n",
    "adaboost = AdaBoostRegressor(n_estimators=50, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "adaboost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = adaboost.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 1.2e-05\n",
      "Mean Absolute Error (MAE): 0.001656\n",
      "Root Mean Squared Error (RMSE): 0.003405\n",
      "R-squared (R2): 0.997574\n",
      "Mean Absolute Percentage Error (MAPE): 0.006196\n",
      "Median Absolute Error (MedAE): 0.00088\n",
      "Max Error: 0.099021\n",
      "Mean Squared Logarithmic Error (MSLE): 7e-06\n",
      "R-squared Adjusted (R2 Adjusted): 0.997419\n",
      "Explained Variance Score: 0.997575\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Initialize GradientBoostingRegressor\n",
    "gradient_boosting = GradientBoostingRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "gradient_boosting.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = gradient_boosting.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/24/ec/ad387100fa3cc2b9b81af0829b5ecfe75ec5bb19dd7c19d4fea06fb81802/xgboost-2.0.3-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from xgboost) (1.11.1)\n",
      "Downloading xgboost-2.0.3-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/99.8 MB 1.3 MB/s eta 0:01:16\n",
      "   ---------------------------------------- 0.3/99.8 MB 2.5 MB/s eta 0:00:40\n",
      "   ---------------------------------------- 0.5/99.8 MB 3.0 MB/s eta 0:00:34\n",
      "   ---------------------------------------- 0.7/99.8 MB 3.4 MB/s eta 0:00:30\n",
      "   ---------------------------------------- 1.0/99.8 MB 4.0 MB/s eta 0:00:25\n",
      "    --------------------------------------- 1.3/99.8 MB 4.3 MB/s eta 0:00:24\n",
      "    --------------------------------------- 1.5/99.8 MB 4.1 MB/s eta 0:00:25\n",
      "    --------------------------------------- 1.6/99.8 MB 4.2 MB/s eta 0:00:24\n",
      "    --------------------------------------- 1.8/99.8 MB 4.1 MB/s eta 0:00:24\n",
      "    --------------------------------------- 1.9/99.8 MB 4.0 MB/s eta 0:00:25\n",
      "    --------------------------------------- 2.1/99.8 MB 3.9 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.3/99.8 MB 3.9 MB/s eta 0:00:26\n",
      "    --------------------------------------- 2.5/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 2.7/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 2.8/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.0/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.1/99.8 MB 3.9 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 3.3/99.8 MB 3.9 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 3.5/99.8 MB 3.8 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 3.7/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 3.9/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.1/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.2/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.4/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.5/99.8 MB 3.9 MB/s eta 0:00:25\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.8 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.8 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.8 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.8 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.8 MB/s eta 0:00:26\n",
      "   - -------------------------------------- 4.6/99.8 MB 3.1 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 4.7/99.8 MB 3.1 MB/s eta 0:00:31\n",
      "   - -------------------------------------- 4.7/99.8 MB 3.0 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 4.8/99.8 MB 3.0 MB/s eta 0:00:32\n",
      "   - -------------------------------------- 4.9/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.0/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.1/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.2/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.4/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.5/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 5.5/99.8 MB 2.9 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 5.7/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 5.8/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 5.9/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.1/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.3/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.4/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.5/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.6/99.8 MB 2.9 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.7/99.8 MB 2.8 MB/s eta 0:00:33\n",
      "   -- ------------------------------------- 6.7/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 6.8/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 6.9/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 7.0/99.8 MB 2.8 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 7.1/99.8 MB 2.7 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 7.2/99.8 MB 2.7 MB/s eta 0:00:34\n",
      "   -- ------------------------------------- 7.3/99.8 MB 2.7 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 7.3/99.8 MB 2.7 MB/s eta 0:00:35\n",
      "   -- ------------------------------------- 7.4/99.8 MB 2.7 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 7.5/99.8 MB 2.7 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 7.6/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 7.6/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 7.7/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 7.9/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.0/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.1/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.2/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.3/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.4/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.6/99.8 MB 2.6 MB/s eta 0:00:36\n",
      "   --- ------------------------------------ 8.7/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 8.9/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.1/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.2/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.3/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.4/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.5/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.6/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.7/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   --- ------------------------------------ 9.9/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.0/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.1/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.3/99.8 MB 2.6 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 10.4/99.8 MB 2.6 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 10.5/99.8 MB 2.6 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 10.6/99.8 MB 2.6 MB/s eta 0:00:34\n",
      "   ---- ----------------------------------- 10.7/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.8/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 10.9/99.8 MB 2.6 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 11.0/99.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 11.2/99.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 11.3/99.8 MB 2.5 MB/s eta 0:00:35\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.5 MB/s eta 0:00:36\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.3 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 11.4/99.8 MB 2.3 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 11.5/99.8 MB 2.3 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 11.6/99.8 MB 2.3 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 11.7/99.8 MB 2.3 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 11.8/99.8 MB 2.3 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 11.9/99.8 MB 2.3 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 12.0/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 12.2/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 12.3/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ---- ----------------------------------- 12.5/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 12.6/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 12.7/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 12.9/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 13.0/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 13.1/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 13.3/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 13.4/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 13.6/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 13.8/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 14.0/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 14.2/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 14.3/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 14.4/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 14.5/99.8 MB 2.2 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 14.6/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 14.8/99.8 MB 2.2 MB/s eta 0:00:40\n",
      "   ----- ---------------------------------- 14.9/99.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 15.0/99.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 15.1/99.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 15.2/99.8 MB 2.3 MB/s eta 0:00:37\n",
      "   ------ --------------------------------- 15.5/99.8 MB 2.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 15.6/99.8 MB 2.4 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 15.9/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.0/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.2/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.3/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.5/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.6/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.8/99.8 MB 2.4 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 16.9/99.8 MB 2.4 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 17.0/99.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 17.1/99.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 17.2/99.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 17.3/99.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------ --------------------------------- 17.4/99.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 17.5/99.8 MB 2.5 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 17.6/99.8 MB 2.5 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 17.7/99.8 MB 2.5 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 17.9/99.8 MB 2.5 MB/s eta 0:00:33\n",
      "   ------- -------------------------------- 18.1/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 18.2/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 18.3/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 18.4/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 18.5/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 18.7/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 18.8/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.0/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.1/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.2/99.8 MB 2.6 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   ------- -------------------------------- 19.4/99.8 MB 2.4 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 19.6/99.8 MB 2.4 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 20.0/99.8 MB 2.5 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 20.3/99.8 MB 2.5 MB/s eta 0:00:32\n",
      "   -------- ------------------------------- 20.7/99.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 20.9/99.8 MB 2.6 MB/s eta 0:00:31\n",
      "   -------- ------------------------------- 21.1/99.8 MB 2.7 MB/s eta 0:00:30\n",
      "   -------- ------------------------------- 21.4/99.8 MB 2.7 MB/s eta 0:00:29\n",
      "   -------- ------------------------------- 21.7/99.8 MB 3.0 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 22.0/99.8 MB 3.1 MB/s eta 0:00:26\n",
      "   -------- ------------------------------- 22.2/99.8 MB 3.2 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 22.5/99.8 MB 3.2 MB/s eta 0:00:25\n",
      "   --------- ------------------------------ 22.7/99.8 MB 3.2 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 23.0/99.8 MB 3.3 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 23.3/99.8 MB 3.4 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 23.6/99.8 MB 3.4 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 23.8/99.8 MB 3.4 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 24.0/99.8 MB 3.4 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 24.3/99.8 MB 3.4 MB/s eta 0:00:23\n",
      "   --------- ------------------------------ 24.5/99.8 MB 3.4 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 24.7/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   --------- ------------------------------ 24.8/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 25.0/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 25.2/99.8 MB 3.6 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 25.3/99.8 MB 3.6 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 25.4/99.8 MB 3.6 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 25.5/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 25.6/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 25.8/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 25.9/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 26.0/99.8 MB 3.5 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 26.1/99.8 MB 3.4 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 3.4 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 3.4 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 26.3/99.8 MB 3.3 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.3/99.8 MB 3.3 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.4/99.8 MB 3.3 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.5/99.8 MB 3.3 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.6/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.7/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.8/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 26.9/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 27.0/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 27.2/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ---------- ----------------------------- 27.3/99.8 MB 3.2 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 27.5/99.8 MB 3.3 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 27.6/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 27.8/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 27.8/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 28.0/99.8 MB 3.3 MB/s eta 0:00:23\n",
      "   ----------- ---------------------------- 28.1/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 28.3/99.8 MB 3.3 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 28.6/99.8 MB 3.4 MB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 28.9/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.1/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.3/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.5/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.9 MB/s eta 0:00:18\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.9 MB/s eta 0:00:19\n",
      "   ----------- ---------------------------- 29.7/99.8 MB 3.5 MB/s eta 0:00:20\n",
      "   ----------- ---------------------------- 29.9/99.8 MB 3.5 MB/s eta 0:00:20\n",
      "   ------------ --------------------------- 30.1/99.8 MB 3.5 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.2/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.4/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.6/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 30.8/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.0/99.8 MB 3.4 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.2/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.4/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.5/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.6/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.8/99.8 MB 3.3 MB/s eta 0:00:21\n",
      "   ------------ --------------------------- 31.9/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.1/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.2/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------ --------------------------- 32.4/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 32.6/99.8 MB 3.2 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 32.8/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 32.9/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 33.1/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 33.2/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 33.3/99.8 MB 3.1 MB/s eta 0:00:22\n",
      "   ------------- -------------------------- 33.4/99.8 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 33.4/99.8 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 33.5/99.8 MB 3.0 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 33.6/99.8 MB 2.9 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 33.7/99.8 MB 2.9 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 33.8/99.8 MB 2.9 MB/s eta 0:00:23\n",
      "   ------------- -------------------------- 33.9/99.8 MB 2.9 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.0/99.8 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.2/99.8 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.3/99.8 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.4/99.8 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.5/99.8 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.6/99.8 MB 2.8 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.7/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   ------------- -------------------------- 34.8/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 34.9/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.1/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.2/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.3/99.8 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 35.3/99.8 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 35.5/99.8 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 35.6/99.8 MB 2.7 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 35.7/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 35.9/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.0/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.2/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.2/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.3/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.3/99.8 MB 2.6 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 36.4/99.8 MB 2.6 MB/s eta 0:00:25\n",
      "   -------------- ------------------------- 36.4/99.8 MB 2.7 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.6 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.6 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.6 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.6 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.6 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.6 MB/s eta 0:00:24\n",
      "   -------------- ------------------------- 36.5/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 36.6/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 36.7/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 36.8/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 37.0/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 37.0/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 37.2/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   -------------- ------------------------- 37.3/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 37.4/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 37.6/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 37.7/99.8 MB 2.5 MB/s eta 0:00:26\n",
      "   --------------- ------------------------ 38.0/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 38.2/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 38.4/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 38.6/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 38.7/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 38.9/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 39.1/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 39.3/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 39.5/99.8 MB 2.5 MB/s eta 0:00:25\n",
      "   --------------- ------------------------ 39.7/99.8 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 39.9/99.8 MB 2.5 MB/s eta 0:00:24\n",
      "   ---------------- ----------------------- 40.1/99.8 MB 2.7 MB/s eta 0:00:23\n",
      "   ---------------- ----------------------- 40.3/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 40.5/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 40.7/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 41.0/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 41.3/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 41.5/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 41.6/99.8 MB 2.7 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 41.8/99.8 MB 2.8 MB/s eta 0:00:22\n",
      "   ---------------- ----------------------- 42.0/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 42.2/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ---------------- ----------------------- 42.4/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 42.6/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 42.8/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 43.0/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 43.2/99.8 MB 2.8 MB/s eta 0:00:21\n",
      "   ----------------- ---------------------- 43.4/99.8 MB 2.8 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 43.6/99.8 MB 2.9 MB/s eta 0:00:20\n",
      "   ----------------- ---------------------- 43.8/99.8 MB 2.9 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 44.1/99.8 MB 3.0 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 44.4/99.8 MB 3.1 MB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 44.6/99.8 MB 3.1 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 44.9/99.8 MB 3.2 MB/s eta 0:00:18\n",
      "   ------------------ --------------------- 45.1/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.2/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.4/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.5/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.6/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.7/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.8/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 45.9/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.1/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.2/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.3/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.4/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.5/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.5/99.8 MB 3.2 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.6/99.8 MB 3.3 MB/s eta 0:00:17\n",
      "   ------------------ --------------------- 46.8/99.8 MB 3.6 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 47.0/99.8 MB 3.7 MB/s eta 0:00:15\n",
      "   ------------------ --------------------- 47.2/99.8 MB 3.8 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 47.5/99.8 MB 3.9 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 47.9/99.8 MB 4.0 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/99.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/99.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/99.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/99.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/99.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.3/99.8 MB 4.1 MB/s eta 0:00:13\n",
      "   ------------------- -------------------- 48.5/99.8 MB 3.7 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 48.9/99.8 MB 3.8 MB/s eta 0:00:14\n",
      "   ------------------- -------------------- 49.5/99.8 MB 4.0 MB/s eta 0:00:13\n",
      "   -------------------- ------------------- 50.3/99.8 MB 4.2 MB/s eta 0:00:12\n",
      "   -------------------- ------------------- 51.6/99.8 MB 4.6 MB/s eta 0:00:11\n",
      "   --------------------- ------------------ 53.5/99.8 MB 5.6 MB/s eta 0:00:09\n",
      "   ---------------------- ----------------- 56.1/99.8 MB 8.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 59.8/99.8 MB 46.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 65.0/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 69.2/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 73.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 77.5/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 81.6/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 85.4/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.4/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 93.7/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  97.8/99.8 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 21.8 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error (MSE): 4e-06\n",
      "Mean Absolute Error (MAE): 0.000387\n",
      "Root Mean Squared Error (RMSE): 0.002066\n",
      "R-squared (R2): 0.999107\n",
      "Mean Absolute Percentage Error (MAPE): 0.001576\n",
      "Median Absolute Error (MedAE): 7.8e-05\n",
      "Max Error: 0.146001\n",
      "Mean Squared Logarithmic Error (MSLE): 3e-06\n",
      "R-squared Adjusted (R2 Adjusted): 0.99905\n",
      "Explained Variance Score: 0.999107\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Initialize XGBRegressor\n",
    "xgboost = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = xgboost.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", round(mse,6))\n",
    "print(\"Mean Absolute Error (MAE):\", round(mae,6))\n",
    "print(\"Root Mean Squared Error (RMSE):\", round(rmse,6))\n",
    "print(\"R-squared (R2):\", round(r2,6))\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", round(mape,6))\n",
    "print(\"Median Absolute Error (MedAE):\", round(medae,6))\n",
    "print(\"Max Error:\", round(max_err,6))\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", round(msle,6))\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", round(r2_adj,6))\n",
    "print(\"Explained Variance Score:\", round(evs,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/e4/14/d795bb156f8cc10eb1dcfe1332b7dbb8405b634688980aa9be8f885cc888/tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.16.1 from https://files.pythonhosted.org/packages/e0/36/6278e4e7e69a90c00e0f82944d8f2713dd85a69d1add455d9e50446837ab/tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/a2/ad/e0d3c824784ff121c03cc031f944bc7e139a8f1870ffd2845cc2dd76f6c4/absl_py-2.1.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for astunparse>=1.6.0 from https://files.pythonhosted.org/packages/2b/03/13dde6512ad7b4557eb792fbcf0c653af6076b81e5941d36ec61f7ce6028/astunparse-1.6.3-py2.py3-none-any.whl.metadata\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.5.26 from https://files.pythonhosted.org/packages/41/f0/7e988a019bc54b2dbd0ad4182ef2d53488bb02e58694cd79d61369e85900/flatbuffers-24.3.25-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 from https://files.pythonhosted.org/packages/fa/39/5aae571e5a5f4de9c3445dae08a530498e5c53b0e74410eeeb0991c79047/gast-0.5.4-py3-none-any.whl.metadata\n",
      "  Downloading gast-0.5.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for google-pasta>=0.1.1 from https://files.pythonhosted.org/packages/a3/de/c648ef6835192e6e2cc03f40b19eeda4382c49b5bafb43d88b931c4c74ac/google_pasta-0.2.0-py3-none-any.whl.metadata\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for h5py>=3.10.0 from https://files.pythonhosted.org/packages/d8/5e/b7b83cfe60504cc4d24746aed04353af7ea8ec104e597e5ae71b8d0390cb/h5py-3.11.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/0b/2d/3f480b1e1d31eb3d6de5e3ef641954e5c67430d5ac93b7fa7e07589576c7/libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for ml-dtypes~=0.3.1 from https://files.pythonhosted.org/packages/a4/db/1784b87285588788170f87e987bfb4bda218d62a70a81ebb66c94e7f9b95/ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for opt-einsum>=2.3.2 from https://files.pythonhosted.org/packages/bc/19/404708a7e54ad2798907210462fd950c3442ea51acc8790f3da48d2bee8b/opt_einsum-3.3.0-py3-none-any.whl.metadata\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/ad/6e/1bed3b7c904cc178cb8ee8dbaf72934964452b3de95b7a63412591edb93c/protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for termcolor>=1.1.0 from https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/3e/73/5e69f620288b46de1f3428b3699397bfd6b9d4a5de944345046ec3ce3808/grpcio-1.63.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.63.0-cp311-cp311-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorboard<2.17,>=2.16 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorboard<2.17,>=2.16 from https://files.pythonhosted.org/packages/3a/d0/b97889ffa769e2d1fdebb632084d5e8b53fc299d43a537acee7ec0c021a3/tensorboard-2.16.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.0.0 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for keras>=3.0.0 from https://files.pythonhosted.org/packages/8d/44/c604ecc5c9993b6574a681f2f505e980725871a89cfd9e48597b12ccb506/keras-3.3.3-py3-none-any.whl.metadata\n",
      "  Downloading keras-3.3.3-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-io-gcs-filesystem>=0.23.1 from https://files.pythonhosted.org/packages/ac/4e/9566a313927be582ca99455a9523a097c7888fc819695bdc08415432b202/tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.38.4)\n",
      "Collecting rich (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for rich from https://files.pythonhosted.org/packages/87/67/a37f6214d0e9fe57f6ae54b2956d550ca8365857f42a1ce0392bb21d9410/rich-13.7.1-py3-none-any.whl.metadata\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for namex from https://files.pythonhosted.org/packages/73/59/7854fbfb59f8ae35483ce93493708be5942ebb6328cd85b3a609df629736/namex-0.0.8-py3-none-any.whl.metadata\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for optree from https://files.pythonhosted.org/packages/8f/db/e05a35451d4ba30fdc65ef168dfdc68a6939ea6afdc0101e3e77f97e1547/optree-0.11.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading optree-0.11.0-cp311-cp311-win_amd64.whl.metadata (46 kB)\n",
      "     ---------------------------------------- 0.0/46.2 kB ? eta -:--:--\n",
      "     ---------------------------------------- 46.2/46.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2023.11.17)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/7a/13/e503968fefabd4c6b2650af21e110aa8466fe21432cd7c43a84577a89438/tensorboard_data_server-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\halimeh\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.16.1-cp311-cp311-win_amd64.whl (2.1 kB)\n",
      "Downloading tensorflow_intel-2.16.1-cp311-cp311-win_amd64.whl (377.0 MB)\n",
      "   ---------------------------------------- 0.0/377.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.8/377.0 MB 88.6 MB/s eta 0:00:05\n",
      "    --------------------------------------- 8.3/377.0 MB 105.1 MB/s eta 0:00:04\n",
      "   - ------------------------------------- 12.6/377.0 MB 110.0 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 16.5/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 20.6/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 24.7/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 28.8/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 32.8/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 37.3/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 41.5/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 45.9/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 50.3/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 54.9/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ------ -------------------------------- 59.5/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 64.1/377.0 MB 93.9 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 68.9/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 72.4/377.0 MB 93.0 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 75.1/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 78.8/377.0 MB 73.1 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 82.8/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 82.8/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 82.8/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 82.8/377.0 MB 81.8 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 84.0/377.0 MB 34.4 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 85.9/377.0 MB 29.8 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 87.3/377.0 MB 27.3 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 90.1/377.0 MB 27.3 MB/s eta 0:00:11\n",
      "   ---------- ----------------------------- 95.0/377.0 MB 59.5 MB/s eta 0:00:05\n",
      "   ---------- --------------------------- 101.0/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ---------- --------------------------- 105.7/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ----------- -------------------------- 111.0/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ----------- -------------------------- 116.3/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ------------ ------------------------- 121.1/377.0 MB 110.0 MB/s eta 0:00:03\n",
      "   ------------ ------------------------- 126.7/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ------------- ------------------------ 131.6/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   ------------- ------------------------ 136.5/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   -------------- ----------------------- 142.1/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   -------------- ----------------------- 147.1/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   --------------- ---------------------- 152.2/377.0 MB 108.8 MB/s eta 0:00:03\n",
      "   --------------- ---------------------- 157.3/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ---------------- --------------------- 162.1/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ---------------- --------------------- 167.1/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------- -------------------- 171.9/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------------ -------------------- 176.5/377.0 MB 93.9 MB/s eta 0:00:03\n",
      "   ------------------ -------------------- 181.2/377.0 MB 93.0 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 186.0/377.0 MB 93.0 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 190.7/377.0 MB 93.0 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 195.5/377.0 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 200.3/377.0 MB 93.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------ 202.9/377.0 MB 81.8 MB/s eta 0:00:03\n",
      "   --------------------- ----------------- 207.7/377.0 MB 81.8 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 212.7/377.0 MB 93.9 MB/s eta 0:00:02\n",
      "   ---------------------- --------------- 218.4/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ---------------------- --------------- 223.8/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------------- -------------- 229.1/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ----------------------- -------------- 234.2/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ------------------------ ------------- 239.4/377.0 MB 110.0 MB/s eta 0:00:02\n",
      "   ------------------------ ------------- 245.1/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------------------- ------------ 250.3/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   ------------------------- ------------ 255.4/377.0 MB 108.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 259.5/377.0 MB 93.0 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 263.0/377.0 MB 81.8 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 266.3/377.0 MB 72.6 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 269.4/377.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 273.2/377.0 MB 73.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 275.6/377.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 278.0/377.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 280.5/377.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 283.1/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 285.5/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 288.4/377.0 MB 54.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 291.2/377.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 294.3/377.0 MB 59.5 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 297.7/377.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 301.1/377.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 303.0/377.0 MB 65.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 304.2/377.0 MB 50.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 305.1/377.0 MB 40.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 306.2/377.0 MB 36.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 307.5/377.0 MB 34.6 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 309.2/377.0 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 311.0/377.0 MB 28.4 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 313.4/377.0 MB 31.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 315.7/377.0 MB 36.4 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 318.5/377.0 MB 46.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 322.4/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 326.0/377.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 331.0/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 336.2/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- --- 339.9/377.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 343.1/377.0 MB 93.0 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 345.8/377.0 MB 72.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 349.6/377.0 MB 73.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 353.6/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 357.9/377.0 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 362.4/377.0 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 364.3/377.0 MB 81.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 366.9/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  369.6/377.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.7/377.0 MB 59.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  376.5/377.0 MB 73.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  377.0/377.0 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 377.0/377.0 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.7/133.7 kB 8.2 MB/s eta 0:00:00\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Downloading grpcio-1.63.0-cp311-cp311-win_amd64.whl (3.9 MB)\n",
      "   ---------------------------------------- 0.0/3.9 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 3.0/3.9 MB 64.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  3.9/3.9 MB 62.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.9/3.9 MB 41.8 MB/s eta 0:00:00\n",
      "Downloading h5py-3.11.0-cp311-cp311-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------  3.0/3.0 MB 95.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 47.9 MB/s eta 0:00:00\n",
      "Downloading keras-3.3.3-py3-none-any.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 23.5 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.5/26.4 MB 46.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 3.8/26.4 MB 48.2 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 6.6/26.4 MB 52.4 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 8.5/26.4 MB 49.5 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.0/26.4 MB 45.7 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 11.8/26.4 MB 46.9 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.1/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.4 MB 46.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 18.9/26.4 MB 43.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.5/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 24.3/26.4 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.4/26.4 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 29.7 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.3.2-cp311-cp311-win_amd64.whl (127 kB)\n",
      "   ---------------------------------------- 0.0/127.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 127.7/127.7 kB 7.3 MB/s eta 0:00:00\n",
      "Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.5/65.5 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 413.4/413.4 kB 26.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 2.5/5.5 MB 52.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.5/5.5 MB 58.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 43.8 MB/s eta 0:00:00\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 46.1 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.11.0-cp311-cp311-win_amd64.whl (245 kB)\n",
      "   ---------------------------------------- 0.0/245.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 245.0/245.0 kB 15.7 MB/s eta 0:00:00\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 240.7/240.7 kB ? eta 0:00:00\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, h5py, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 3.9.0\n",
      "    Uninstalling h5py-3.9.0:\n",
      "      Successfully uninstalled h5py-3.9.0\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.5.4 google-pasta-0.2.0 grpcio-1.63.0 h5py-3.11.0 keras-3.3.3 libclang-18.1.1 ml-dtypes-0.3.2 namex-0.0.8 opt-einsum-3.3.0 optree-0.11.0 protobuf-4.25.3 rich-13.7.1 tensorboard-2.16.2 tensorboard-data-server-0.7.2 tensorflow-2.16.1 tensorflow-intel-2.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Halimeh\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - loss: 0.0019 - mae: 0.0225 - mse: 0.0019 - val_loss: 7.1043e-05 - val_mae: 0.0064 - val_mse: 7.1043e-05\n",
      "Epoch 2/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 5.3076e-05 - mae: 0.0052 - mse: 5.3076e-05 - val_loss: 2.8747e-05 - val_mae: 0.0035 - val_mse: 2.8747e-05\n",
      "Epoch 3/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 3.1739e-05 - mae: 0.0039 - mse: 3.1739e-05 - val_loss: 6.1002e-05 - val_mae: 0.0063 - val_mse: 6.1002e-05\n",
      "Epoch 4/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 3.2760e-05 - mae: 0.0039 - mse: 3.2760e-05 - val_loss: 3.1139e-05 - val_mae: 0.0036 - val_mse: 3.1139e-05\n",
      "Epoch 5/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2.6524e-05 - mae: 0.0036 - mse: 2.6524e-05 - val_loss: 3.8878e-05 - val_mae: 0.0050 - val_mse: 3.8878e-05\n",
      "Epoch 6/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 2.7251e-05 - mae: 0.0036 - mse: 2.7251e-05 - val_loss: 2.9189e-05 - val_mae: 0.0043 - val_mse: 2.9189e-05\n",
      "Epoch 7/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 2.3768e-05 - mae: 0.0035 - mse: 2.3768e-05 - val_loss: 1.6195e-05 - val_mae: 0.0023 - val_mse: 1.6195e-05\n",
      "Epoch 8/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.9428e-05 - mae: 0.0031 - mse: 1.9428e-05 - val_loss: 2.3675e-05 - val_mae: 0.0030 - val_mse: 2.3675e-05\n",
      "Epoch 9/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 1.8709e-05 - mae: 0.0029 - mse: 1.8709e-05 - val_loss: 1.8161e-05 - val_mae: 0.0027 - val_mse: 1.8161e-05\n",
      "Epoch 10/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 7ms/step - loss: 1.6494e-05 - mae: 0.0027 - mse: 1.6494e-05 - val_loss: 1.4708e-05 - val_mae: 0.0022 - val_mse: 1.4708e-05\n",
      "Epoch 11/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6ms/step - loss: 1.5153e-05 - mae: 0.0027 - mse: 1.5153e-05 - val_loss: 1.3219e-05 - val_mae: 0.0022 - val_mse: 1.3219e-05\n",
      "Epoch 12/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.7577e-05 - mae: 0.0029 - mse: 1.7577e-05 - val_loss: 1.6922e-05 - val_mae: 0.0026 - val_mse: 1.6922e-05\n",
      "Epoch 13/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.3814e-05 - mae: 0.0026 - mse: 1.3814e-05 - val_loss: 1.6961e-05 - val_mae: 0.0029 - val_mse: 1.6961e-05\n",
      "Epoch 14/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.4859e-05 - mae: 0.0026 - mse: 1.4859e-05 - val_loss: 2.0657e-05 - val_mae: 0.0036 - val_mse: 2.0657e-05\n",
      "Epoch 15/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.2907e-05 - mae: 0.0025 - mse: 1.2907e-05 - val_loss: 1.4975e-05 - val_mae: 0.0027 - val_mse: 1.4975e-05\n",
      "Epoch 16/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.2648e-05 - mae: 0.0024 - mse: 1.2648e-05 - val_loss: 1.6224e-05 - val_mae: 0.0026 - val_mse: 1.6224e-05\n",
      "Epoch 17/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.2947e-05 - mae: 0.0024 - mse: 1.2947e-05 - val_loss: 1.0602e-05 - val_mae: 0.0019 - val_mse: 1.0602e-05\n",
      "Epoch 18/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.6688e-05 - mae: 0.0026 - mse: 1.6688e-05 - val_loss: 1.4288e-05 - val_mae: 0.0026 - val_mse: 1.4288e-05\n",
      "Epoch 19/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 1.2080e-05 - mae: 0.0023 - mse: 1.2080e-05 - val_loss: 8.8638e-06 - val_mae: 0.0016 - val_mse: 8.8638e-06\n",
      "Epoch 20/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 9.8458e-06 - mae: 0.0021 - mse: 9.8458e-06 - val_loss: 1.4577e-05 - val_mae: 0.0026 - val_mse: 1.4577e-05\n",
      "Epoch 21/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 9.9061e-06 - mae: 0.0021 - mse: 9.9061e-06 - val_loss: 1.5182e-05 - val_mae: 0.0029 - val_mse: 1.5182e-05\n",
      "Epoch 22/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 8.9333e-06 - mae: 0.0020 - mse: 8.9333e-06 - val_loss: 1.0261e-05 - val_mae: 0.0017 - val_mse: 1.0261e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.1284e-06 - mae: 0.0020 - mse: 9.1284e-06 - val_loss: 9.1490e-06 - val_mae: 0.0015 - val_mse: 9.1490e-06\n",
      "Epoch 24/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 7.9622e-06 - mae: 0.0019 - mse: 7.9622e-06 - val_loss: 1.7169e-05 - val_mae: 0.0029 - val_mse: 1.7169e-05\n",
      "Epoch 25/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 1.0891e-05 - mae: 0.0022 - mse: 1.0891e-05 - val_loss: 1.7322e-05 - val_mae: 0.0032 - val_mse: 1.7322e-05\n",
      "Epoch 26/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 1.0056e-05 - mae: 0.0021 - mse: 1.0056e-05 - val_loss: 8.0432e-06 - val_mae: 0.0014 - val_mse: 8.0432e-06\n",
      "Epoch 27/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 9.3834e-06 - mae: 0.0020 - mse: 9.3834e-06 - val_loss: 9.2194e-06 - val_mae: 0.0016 - val_mse: 9.2194e-06\n",
      "Epoch 28/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 8.5697e-06 - mae: 0.0019 - mse: 8.5697e-06 - val_loss: 1.0255e-05 - val_mae: 0.0014 - val_mse: 1.0255e-05\n",
      "Epoch 29/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 8.9511e-06 - mae: 0.0020 - mse: 8.9511e-06 - val_loss: 1.0245e-05 - val_mae: 0.0016 - val_mse: 1.0245e-05\n",
      "Epoch 30/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 7.5344e-06 - mae: 0.0017 - mse: 7.5344e-06 - val_loss: 1.3052e-05 - val_mae: 0.0017 - val_mse: 1.3052e-05\n",
      "Epoch 31/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 9.0372e-06 - mae: 0.0020 - mse: 9.0372e-06 - val_loss: 1.1188e-05 - val_mae: 0.0018 - val_mse: 1.1188e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 7.5405e-06 - mae: 0.0017 - mse: 7.5405e-06 - val_loss: 1.1193e-05 - val_mae: 0.0020 - val_mse: 1.1193e-05\n",
      "Epoch 33/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 9.5556e-06 - mae: 0.0020 - mse: 9.5556e-06 - val_loss: 7.5548e-06 - val_mae: 0.0013 - val_mse: 7.5548e-06\n",
      "Epoch 34/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 7.0076e-06 - mae: 0.0017 - mse: 7.0076e-06 - val_loss: 1.1831e-05 - val_mae: 0.0016 - val_mse: 1.1831e-05\n",
      "Epoch 35/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 7.9884e-06 - mae: 0.0017 - mse: 7.9884e-06 - val_loss: 8.5299e-06 - val_mae: 0.0015 - val_mse: 8.5299e-06\n",
      "Epoch 36/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 7.8160e-06 - mae: 0.0018 - mse: 7.8160e-06 - val_loss: 9.7933e-06 - val_mae: 0.0017 - val_mse: 9.7933e-06\n",
      "Epoch 37/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 7.0434e-06 - mae: 0.0018 - mse: 7.0434e-06 - val_loss: 1.8125e-05 - val_mae: 0.0031 - val_mse: 1.8125e-05\n",
      "Epoch 38/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 7.3132e-06 - mae: 0.0018 - mse: 7.3132e-06 - val_loss: 1.2862e-05 - val_mae: 0.0019 - val_mse: 1.2862e-05\n",
      "Epoch 39/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 7.9913e-06 - mae: 0.0019 - mse: 7.9913e-06 - val_loss: 1.2875e-05 - val_mae: 0.0018 - val_mse: 1.2875e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 8.4518e-06 - mae: 0.0018 - mse: 8.4518e-06 - val_loss: 1.0149e-05 - val_mae: 0.0021 - val_mse: 1.0149e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 5.3639e-06 - mae: 0.0015 - mse: 5.3639e-06 - val_loss: 1.2488e-05 - val_mae: 0.0021 - val_mse: 1.2488e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.8311e-06 - mae: 0.0016 - mse: 6.8311e-06 - val_loss: 9.2575e-06 - val_mae: 0.0015 - val_mse: 9.2575e-06\n",
      "Epoch 43/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - loss: 7.2582e-06 - mae: 0.0016 - mse: 7.2582e-06 - val_loss: 1.1409e-05 - val_mae: 0.0015 - val_mse: 1.1409e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 9.6224e-06 - mae: 0.0018 - mse: 9.6224e-06 - val_loss: 8.3440e-06 - val_mae: 0.0014 - val_mse: 8.3440e-06\n",
      "Epoch 45/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 6.7816e-06 - mae: 0.0016 - mse: 6.7816e-06 - val_loss: 8.1106e-06 - val_mae: 0.0013 - val_mse: 8.1106e-06\n",
      "Epoch 46/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 6.3697e-06 - mae: 0.0016 - mse: 6.3697e-06 - val_loss: 7.9201e-06 - val_mae: 0.0015 - val_mse: 7.9201e-06\n",
      "Epoch 47/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 6.4086e-06 - mae: 0.0015 - mse: 6.4086e-06 - val_loss: 9.9043e-06 - val_mae: 0.0014 - val_mse: 9.9043e-06\n",
      "Epoch 48/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 6.7192e-06 - mae: 0.0016 - mse: 6.7192e-06 - val_loss: 9.8557e-06 - val_mae: 0.0012 - val_mse: 9.8557e-06\n",
      "Epoch 49/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 7.2160e-06 - mae: 0.0018 - mse: 7.2160e-06 - val_loss: 9.8513e-06 - val_mae: 0.0011 - val_mse: 9.8513e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.1546e-06 - mae: 0.0014 - mse: 5.1546e-06 - val_loss: 9.0983e-06 - val_mae: 0.0016 - val_mse: 9.0983e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6.9282e-06 - mae: 0.0016 - mse: 6.9282e-06 - val_loss: 1.0138e-05 - val_mae: 0.0013 - val_mse: 1.0138e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 6.9302e-06 - mae: 0.0016 - mse: 6.9302e-06 - val_loss: 1.0837e-05 - val_mae: 0.0017 - val_mse: 1.0837e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 6.3957e-06 - mae: 0.0015 - mse: 6.3957e-06 - val_loss: 7.6701e-06 - val_mae: 0.0013 - val_mse: 7.6701e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 5.2469e-06 - mae: 0.0015 - mse: 5.2469e-06 - val_loss: 9.3532e-06 - val_mae: 0.0014 - val_mse: 9.3532e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 4.9805e-06 - mae: 0.0015 - mse: 4.9805e-06 - val_loss: 9.0947e-06 - val_mae: 0.0018 - val_mse: 9.0947e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.2219e-06 - mae: 0.0014 - mse: 5.2219e-06 - val_loss: 9.4948e-06 - val_mae: 0.0015 - val_mse: 9.4948e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 6.1906e-06 - mae: 0.0015 - mse: 6.1906e-06 - val_loss: 8.0948e-06 - val_mae: 0.0012 - val_mse: 8.0948e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.0604e-06 - mae: 0.0015 - mse: 5.0604e-06 - val_loss: 1.0507e-05 - val_mae: 0.0018 - val_mse: 1.0507e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.2791e-06 - mae: 0.0015 - mse: 5.2791e-06 - val_loss: 1.2174e-05 - val_mae: 0.0022 - val_mse: 1.2174e-05\n",
      "Epoch 60/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.4508e-06 - mae: 0.0015 - mse: 5.4508e-06 - val_loss: 9.0751e-06 - val_mae: 0.0012 - val_mse: 9.0751e-06\n",
      "Epoch 61/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.4735e-06 - mae: 0.0014 - mse: 5.4735e-06 - val_loss: 9.7460e-06 - val_mae: 0.0015 - val_mse: 9.7460e-06\n",
      "Epoch 62/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.1510e-06 - mae: 0.0015 - mse: 5.1510e-06 - val_loss: 8.2674e-06 - val_mae: 0.0013 - val_mse: 8.2674e-06\n",
      "Epoch 63/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 4.9206e-06 - mae: 0.0015 - mse: 4.9206e-06 - val_loss: 9.9161e-06 - val_mae: 0.0018 - val_mse: 9.9161e-06\n",
      "Epoch 64/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 4.9951e-06 - mae: 0.0015 - mse: 4.9951e-06 - val_loss: 8.3883e-06 - val_mae: 0.0011 - val_mse: 8.3883e-06\n",
      "Epoch 65/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 5.1437e-06 - mae: 0.0014 - mse: 5.1437e-06 - val_loss: 8.7437e-06 - val_mae: 9.9770e-04 - val_mse: 8.7437e-06\n",
      "Epoch 66/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.5011e-06 - mae: 0.0015 - mse: 5.5011e-06 - val_loss: 8.5860e-06 - val_mae: 0.0011 - val_mse: 8.5860e-06\n",
      "Epoch 67/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.4848e-06 - mae: 0.0014 - mse: 4.4848e-06 - val_loss: 9.4420e-06 - val_mae: 0.0017 - val_mse: 9.4420e-06\n",
      "Epoch 68/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.8662e-06 - mae: 0.0015 - mse: 5.8662e-06 - val_loss: 1.1772e-05 - val_mae: 0.0020 - val_mse: 1.1772e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.5013e-06 - mae: 0.0014 - mse: 4.5013e-06 - val_loss: 1.1484e-05 - val_mae: 0.0013 - val_mse: 1.1484e-05\n",
      "Epoch 70/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.3923e-06 - mae: 0.0014 - mse: 5.3923e-06 - val_loss: 1.0702e-05 - val_mae: 0.0015 - val_mse: 1.0702e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 5.6514e-06 - mae: 0.0016 - mse: 5.6514e-06 - val_loss: 1.1166e-05 - val_mae: 0.0020 - val_mse: 1.1166e-05\n",
      "Epoch 72/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.5054e-06 - mae: 0.0014 - mse: 4.5054e-06 - val_loss: 1.0622e-05 - val_mae: 0.0012 - val_mse: 1.0622e-05\n",
      "Epoch 73/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 4.4442e-06 - mae: 0.0014 - mse: 4.4442e-06 - val_loss: 1.0932e-05 - val_mae: 0.0015 - val_mse: 1.0932e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 4.8126e-06 - mae: 0.0014 - mse: 4.8126e-06 - val_loss: 8.7849e-06 - val_mae: 0.0012 - val_mse: 8.7849e-06\n",
      "Epoch 75/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.8187e-06 - mae: 0.0013 - mse: 3.8187e-06 - val_loss: 1.1308e-05 - val_mae: 0.0015 - val_mse: 1.1308e-05\n",
      "Epoch 76/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.4832e-06 - mae: 0.0014 - mse: 4.4832e-06 - val_loss: 1.2107e-05 - val_mae: 0.0015 - val_mse: 1.2107e-05\n",
      "Epoch 77/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.4643e-06 - mae: 0.0015 - mse: 5.4643e-06 - val_loss: 9.7032e-06 - val_mae: 0.0012 - val_mse: 9.7032e-06\n",
      "Epoch 78/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.4554e-06 - mae: 0.0014 - mse: 4.4554e-06 - val_loss: 1.0077e-05 - val_mae: 0.0014 - val_mse: 1.0077e-05\n",
      "Epoch 79/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.7377e-06 - mae: 0.0014 - mse: 4.7377e-06 - val_loss: 9.0104e-06 - val_mae: 0.0013 - val_mse: 9.0104e-06\n",
      "Epoch 80/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.0147e-06 - mae: 0.0013 - mse: 4.0147e-06 - val_loss: 1.1085e-05 - val_mae: 0.0014 - val_mse: 1.1085e-05\n",
      "Epoch 81/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 7.0479e-06 - mae: 0.0016 - mse: 7.0479e-06 - val_loss: 8.1168e-06 - val_mae: 0.0011 - val_mse: 8.1168e-06\n",
      "Epoch 82/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.0429e-06 - mae: 0.0013 - mse: 4.0429e-06 - val_loss: 1.3980e-05 - val_mae: 0.0025 - val_mse: 1.3980e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.2824e-06 - mae: 0.0014 - mse: 4.2824e-06 - val_loss: 8.9235e-06 - val_mae: 0.0013 - val_mse: 8.9235e-06\n",
      "Epoch 84/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.9508e-06 - mae: 0.0013 - mse: 3.9508e-06 - val_loss: 9.9951e-06 - val_mae: 0.0012 - val_mse: 9.9951e-06\n",
      "Epoch 85/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.6923e-06 - mae: 0.0013 - mse: 4.6923e-06 - val_loss: 1.0902e-05 - val_mae: 0.0014 - val_mse: 1.0902e-05\n",
      "Epoch 86/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.9765e-06 - mae: 0.0013 - mse: 3.9765e-06 - val_loss: 9.7520e-06 - val_mae: 0.0014 - val_mse: 9.7520e-06\n",
      "Epoch 87/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.8311e-06 - mae: 0.0014 - mse: 4.8311e-06 - val_loss: 1.1029e-05 - val_mae: 0.0014 - val_mse: 1.1029e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.3132e-06 - mae: 0.0015 - mse: 5.3132e-06 - val_loss: 1.0873e-05 - val_mae: 0.0019 - val_mse: 1.0873e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.5616e-06 - mae: 0.0014 - mse: 4.5616e-06 - val_loss: 9.1054e-06 - val_mae: 0.0012 - val_mse: 9.1054e-06\n",
      "Epoch 90/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.9605e-06 - mae: 0.0013 - mse: 3.9605e-06 - val_loss: 9.5368e-06 - val_mae: 0.0013 - val_mse: 9.5368e-06\n",
      "Epoch 91/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 5.5768e-06 - mae: 0.0014 - mse: 5.5768e-06 - val_loss: 9.5578e-06 - val_mae: 0.0013 - val_mse: 9.5578e-06\n",
      "Epoch 92/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.8539e-06 - mae: 0.0013 - mse: 3.8539e-06 - val_loss: 1.0676e-05 - val_mae: 0.0017 - val_mse: 1.0676e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.4930e-06 - mae: 0.0014 - mse: 4.4930e-06 - val_loss: 9.6498e-06 - val_mae: 0.0015 - val_mse: 9.6498e-06\n",
      "Epoch 94/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.2501e-06 - mae: 0.0013 - mse: 4.2501e-06 - val_loss: 1.2330e-05 - val_mae: 0.0022 - val_mse: 1.2330e-05\n",
      "Epoch 95/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.2101e-06 - mae: 0.0013 - mse: 4.2101e-06 - val_loss: 9.3069e-06 - val_mae: 0.0014 - val_mse: 9.3069e-06\n",
      "Epoch 96/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.7614e-06 - mae: 0.0013 - mse: 3.7614e-06 - val_loss: 8.7289e-06 - val_mae: 0.0011 - val_mse: 8.7289e-06\n",
      "Epoch 97/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.5632e-06 - mae: 0.0014 - mse: 4.5632e-06 - val_loss: 1.1570e-05 - val_mae: 0.0016 - val_mse: 1.1570e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.0719e-06 - mae: 0.0013 - mse: 4.0719e-06 - val_loss: 1.0182e-05 - val_mae: 0.0012 - val_mse: 1.0182e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 4.0183e-06 - mae: 0.0013 - mse: 4.0183e-06 - val_loss: 9.2183e-06 - val_mae: 0.0011 - val_mse: 9.2183e-06\n",
      "Epoch 100/100\n",
      "\u001b[1m885/885\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 3.6643e-06 - mae: 0.0012 - mse: 3.6643e-06 - val_loss: 1.0433e-05 - val_mae: 0.0013 - val_mse: 1.0433e-05\n",
      "\u001b[1m277/277\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "Mean Squared Error (MSE): 7.862920207668737e-06\n",
      "Mean Absolute Error (MAE): 0.0012659386200401055\n",
      "Root Mean Squared Error (RMSE): 0.0028040899072013965\n",
      "R-squared (R2): 0.9983552128305868\n",
      "Mean Absolute Percentage Error (MAPE): 0.004739819540890415\n",
      "Median Absolute Error (MedAE): 0.0008935153484344593\n",
      "Max Error: 0.1235278759527644\n",
      "Mean Squared Logarithmic Error (MSLE): 4.883722113283707e-06\n",
      "R-squared Adjusted (R2 Adjusted): 0.998249965443754\n",
      "Explained Variance Score: 0.9983979259542273\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define input_shape based on the number of features in data\n",
    "input_shape = X_train.shape[1]\n",
    "# Initialize the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # Output layer for regression task\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mse'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_split=0.2, batch_size=32)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
    "medae = median_absolute_error(y_test, y_pred)\n",
    "max_err = max_error(y_test, y_pred)\n",
    "msle = mean_squared_log_error(y_test, y_pred)\n",
    "r2_adj = 1 - (1-r2) * (len(y_test)-1) / (len(y_test) - X_test.shape[1] - 1)\n",
    "evs = explained_variance_score(y_test, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
    "print(\"R-squared (R2):\", r2)\n",
    "print(\"Mean Absolute Percentage Error (MAPE):\", mape)\n",
    "print(\"Median Absolute Error (MedAE):\", medae)\n",
    "print(\"Max Error:\", max_err)\n",
    "print(\"Mean Squared Logarithmic Error (MSLE):\", msle)\n",
    "print(\"R-squared Adjusted (R2 Adjusted):\", r2_adj)\n",
    "print(\"Explained Variance Score:\", evs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
